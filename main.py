from slack_sender import send_to_slack
from llm_reporter import get_llm_report
from naver_finance_crawler import fetch_kospi_daily, fetch_sector_etf_daily, fetch_industry_info_by_stock_code
from naver_news_crawler import EnhancedNewsCollector
from news_api_caller import match_news_before_events
from seibro_disclosure_scraper import fetch_disclosures_with_fallback, match_disclosures_before_events
import pandas as pd
import os
import requests
from datetime import datetime, timedelta
import random
import json
import traceback
from typing import Dict, List, Tuple, Optional
from stock_database import get_stock_database, add_stock_entry

class CRAGAnalyzer:
    """ê°•í™”ëœ CRAG ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.client_id = os.getenv("NAVER_CLIENT_ID", "JEuS9xkuWGpP40lsI9Kz")
        self.client_secret = os.getenv("NAVER_CLIENT_SECRET", "I6nujCm0xF")
        self.slack_url = os.getenv("SLACK_WEBHOOK_URL", "https://hooks.slack.com/services/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")
        
    def robust_fetch_intraday_price(self, stock_code: str, date: str) -> pd.DataFrame:
        """ê°•ê±´í•œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            from naver_finance_crawler import fetch_intraday_price
            df = fetch_intraday_price(stock_code, date)
            if len(df) > 0:
                print(f"âœ… ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ {len(df)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ")
                return df
        except Exception as e:
            print(f"âš ï¸ ë„¤ì´ë²„ ê¸ˆìœµ ì‹¤íŒ¨: {e}")
        
        print("ğŸ”„ í˜„ì‹¤ì ì¸ ëª¨ì˜ ë°ì´í„° ìƒì„±ìœ¼ë¡œ ëŒ€ì²´")
        return self.generate_realistic_mock_data(stock_code, date)

    def generate_realistic_mock_data(self, stock_code: str, date: str) -> pd.DataFrame:
        """í˜„ì‹¤ì ì¸ ëª¨ì˜ ë°ì´í„° ìƒì„±"""
        base_prices = {
            "005930": 60000, "000660": 120000, "042700": 45000,
            "035420": 180000, "012450": 850000, "373220": 95000,
            "207940": 45000, "006400": 28000, "051910": 850000
        }
        base_price = base_prices.get(stock_code, 50000)
        
        start_time = datetime.strptime(f"{date} 09:00", "%Y-%m-%d %H:%M")
        times, prices, volumes = [], [], []
        current_price = base_price
        
        # ì •êµí•œ ì¥ì¤‘ ì‹œë®¬ë ˆì´ì…˜
        for i in range(390):
            current_time = start_time + timedelta(minutes=i)
            if 12 <= current_time.hour < 13:  # ì ì‹¬ì‹œê°„ ì œì™¸
                continue
                
            # ì‹œê°„ëŒ€ë³„ ë³€ë™ì„± ì¡°ì •
            if 9 <= current_time.hour < 10:  # ê°œì¥ ì´ˆë°˜ ë†’ì€ ë³€ë™ì„±
                volatility = 0.005
            elif 10 <= current_time.hour < 15:  # ì •ê·œì¥ ì¤‘ê°„
                volatility = 0.003
            else:  # ë§ˆê° ì „ ë³€ë™ì„± ì¦ê°€
                volatility = 0.004
                
            change_rate = random.gauss(0, volatility)
            current_price *= (1 + change_rate)
            current_price = max(int(current_price), 1000)
            
            # ê±°ë˜ëŸ‰ íŒ¨í„´ (ê°œì¥/ë§ˆê° ì‹œ ì¦ê°€)
            if 9 <= current_time.hour < 10 or current_time.hour >= 15:
                volume = random.randint(50000, 500000)
            else:
                volume = random.randint(10000, 200000)
            
            times.append(current_time)
            prices.append(current_price)
            volumes.append(volume)
        
        # ì˜ë„ì  ì´ë²¤íŠ¸ ìƒì„± (ë” í˜„ì‹¤ì )
        event_count = random.randint(2, 4)
        event_indices = random.sample(range(50, len(prices)-50), event_count)
        
        for idx in event_indices:
            event_type = random.choice(['strong_up', 'strong_down', 'volume_spike'])
            
            if event_type == 'strong_up':
                for j in range(idx, min(idx+20, len(prices))):
                    prices[j] *= 1.003
                    volumes[j] = int(volumes[j] * 1.8)
            elif event_type == 'strong_down':
                for j in range(idx, min(idx+20, len(prices))):
                    prices[j] *= 0.997
                    volumes[j] = int(volumes[j] * 2.0)
            else:  # volume_spike
                for j in range(idx, min(idx+10, len(prices))):
                    volumes[j] = int(volumes[j] * 3.0)
        
        df = pd.DataFrame({
            'datetime': times,
            'price': [int(p) for p in prices],
            'volume': volumes
        })
        
        print(f"ğŸ“Š í˜„ì‹¤ì  ëª¨ì˜ ë°ì´í„° ìƒì„±: {len(df)}ê°œ ì‹œì , ì´ë²¤íŠ¸ {event_count}ê°œ í¬í•¨")
        return df

    def enhanced_detect_price_events_by_day(self, df: pd.DataFrame, threshold=0.005) -> pd.DataFrame:
        """í–¥ìƒëœ ì´ë²¤íŠ¸ ê°ì§€ (ë‹¤ì¤‘ ì¡°ê±´)"""
        if df.empty:
            return pd.DataFrame()
            
        df = df.copy().sort_values("datetime").reset_index(drop=True)
        start_price = df.iloc[0]['price']
        
        # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        df['pct_from_start'] = (df['price'] - start_price) / start_price
        df['pct_change'] = df['price'].pct_change()
        df['ma_5'] = df['price'].rolling(window=5, min_periods=1).mean()
        df['ma_20'] = df['price'].rolling(window=20, min_periods=1).mean()
        df['vol_ma'] = df['volume'].rolling(window=10, min_periods=1).mean()
        df['vol_ratio'] = df['volume'] / df['vol_ma']
        
        # RSI ê³„ì‚°
        delta = df['price'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        def detect_advanced_event(row, index):
            events = []
            
            # 1. ê°€ê²© ê¸°ë°˜ ì´ë²¤íŠ¸
            if abs(row['pct_from_start']) >= threshold:
                direction = "ìƒìŠ¹" if row['pct_from_start'] > 0 else "í•˜ë½"
                strength = "ê°•" if abs(row['pct_from_start']) >= threshold * 1.5 else "ì•½"
                events.append(f"{strength}{direction}")
            
            # 2. ë‹¨ê¸° ê¸‰ë³€ë™
            if index >= 10:
                recent_change = (row['price'] - df.iloc[index-10]['price']) / df.iloc[index-10]['price']
                if abs(recent_change) >= 0.008:
                    events.append("ê¸‰ìƒìŠ¹" if recent_change > 0 else "ê¸‰í•˜ë½")
            
            # 3. ê±°ë˜ëŸ‰ ì´ìƒ
            if not pd.isna(row['vol_ratio']) and row['vol_ratio'] >= 2.0:
                price_change = row['pct_change']
                if abs(price_change) >= 0.002:
                    events.append("ê±°ë˜ëŸ‰í­ì¦ìƒìŠ¹" if price_change > 0 else "ê±°ë˜ëŸ‰í­ì¦í•˜ë½")
                else:
                    events.append("ê±°ë˜ëŸ‰í­ì¦")
            
            # 4. ì´ë™í‰ê·  ëŒíŒŒ
            if index > 0 and not pd.isna(row['ma_20']):
                prev_vs_ma = (df.iloc[index-1]['price'] - df.iloc[index-1]['ma_20']) / df.iloc[index-1]['ma_20']
                curr_vs_ma = (row['price'] - row['ma_20']) / row['ma_20']
                
                if prev_vs_ma <= 0 and curr_vs_ma > 0.003:
                    events.append("MAëŒíŒŒìƒìŠ¹")
                elif prev_vs_ma >= 0 and curr_vs_ma < -0.003:
                    events.append("MAì´íƒˆí•˜ë½")
            
            # 5. RSI ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„
            if not pd.isna(row['rsi']):
                if row['rsi'] >= 80:
                    events.append("RSIê³¼ë§¤ìˆ˜")
                elif row['rsi'] <= 20:
                    events.append("RSIê³¼ë§¤ë„")
            
            return ", ".join(events) if events else None
        
        df['event_type'] = [detect_advanced_event(row, i) for i, row in df.iterrows()]
        events = df[df['event_type'].notnull()][['datetime', 'price', 'volume', 'pct_from_start', 'vol_ratio', 'rsi', 'event_type']]
        
        print(f"ğŸ¯ ê³ ë„í™” ì´ë²¤íŠ¸ ê°ì§€: {len(events)}ê°œ (ì„ê³„ê°’: {threshold*100:.1f}%)")
        if not events.empty:
            print(f"   ì£¼ìš” ì´ë²¤íŠ¸: {events['event_type'].value_counts().head(3).to_dict()}")
        
        return events

    def load_crag_template(self) -> str:
        """CRAG í…œí”Œë¦¿ ë¡œë“œ (ê°•í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬)"""
        template_paths = ["crag_prompt_template.md", "templates/crag_prompt_template.md", "./crag_prompt_template.md"]
        
        for path in template_paths:
            try:
                with open(path, "r", encoding="utf-8") as f:
                    template_content = f.read()
                    print(f"âœ… í…œí”Œë¦¿ ë¡œë“œ ì„±ê³µ: {path}")
                    
                    # í…œí”Œë¦¿ ë³€ìˆ˜ ê²€ì¦
                    import re
                    template_vars = re.findall(r'\{([^}]+)\}', template_content)
                    print(f"ğŸ“‹ í…œí”Œë¦¿ ë³€ìˆ˜ í™•ì¸: {len(template_vars)}ê°œ")
                    
                    return template_content
            except FileNotFoundError:
                print(f"ğŸ“ í…œí”Œë¦¿ íŒŒì¼ ì—†ìŒ: {path}")
                continue
            except Exception as e:
                print(f"âš ï¸ í…œí”Œë¦¿ ë¡œë“œ ì˜¤ë¥˜ ({path}): {e}")
                continue
        
        # ê¸°ë³¸ í…œí”Œë¦¿ ë°˜í™˜ (ì›ë³¸ í…œí”Œë¦¿ ê¸°ë°˜)
        print("ğŸ”„ ê¸°ë³¸ ë‚´ì¥ í…œí”Œë¦¿ ì‚¬ìš©")
        return '''
ğŸ“Œ **ìš”ì•½ ë¶„ì„**  
- ì£¼ê°€: {summary_price}  
- ë‰´ìŠ¤ ì˜í–¥: ê°ì„± ì ìˆ˜ {sentiment_score:+.2f}, ëŒ€ë¶€ë¶„ {news_timing_comment}  
- ì‹œì¥: {kospi_info}, ì—…ì¢…/ETF: {industry_info}, {etf_info}

---

### 1ï¸âƒ£ ì£¼ê°€ ì´ë²¤íŠ¸ ìš”ì•½

{event_table}

**í•´ì„**: {event_insight}

---

### 2ï¸âƒ£ ë‰´ìŠ¤ ì˜í–¥ë ¥ ë¶„ì„

- ê°ì„± ì ìˆ˜: **{sentiment_score:+.2f} ({sentiment_direction})**
- ì£¼ìš” ë‰´ìŠ¤:
{top_news_titles}
- ë‰´ìŠ¤ ë°œí‘œ ì‹œì : ëŒ€ë¶€ë¶„ **{news_timing_comment}**
- **í•´ì„**: {impact_summary}

---

### 3ï¸âƒ£ ê²½ìŸì‚¬ ë¶„ì„

{competitor_summary}

---

### 4ï¸âƒ£ ì‹œì¥ ë¹„êµ

- ì½”ìŠ¤í”¼: {kospi_info}
- ë™ì¼ ì—…ì¢…: {industry_info}
- ETF: {etf_info}

---

### 5ï¸âƒ£ íˆ¬ì ì‹œì‚¬ì 

- **ë‹¨ê¸°**: {insight_short}
- **ì¤‘ê¸°**: {insight_mid}
- **ë¦¬ìŠ¤í¬**: {risk_warning}

---

ğŸ“ **í–¥í›„ í•„ìš” ì •ë³´**
- ì—…ì¢… ë‚´ ê²½ìŸì‚¬ ë¶„ì„
- ì£¼ìš” ê¸°ì—… ì¬ë¬´ ìš”ì•½
- ê³µì‹œ ì„¸ë¶€ë‚´ìš© ìš”ì•½ ë° ì˜í–¥ ì¶”ì •
- ê¸°ê´€/ì™¸êµ­ì¸ ìˆ˜ê¸‰ ë°ì´í„°

---

âœ³ï¸ *ë³¸ ë¦¬í¬íŠ¸ëŠ” ìë™í™”ëœ LLM ë¶„ì„ì— ê¸°ë°˜í•˜ë©°, íˆ¬ì íŒë‹¨ì€ ì‚¬ìš©ì ì±…ì„ì…ë‹ˆë‹¤.*
'''

    def enhanced_comprehensive_analysis_v3(self, events_df, matched_news_dict, matched_disclosures_dict, 
                                          stock_name: str, date: str, news_impact: dict = None,
                                          competitor_news: list = None, 
                                          kospi_info: str = "", etf_info: str = "", industry_info: str = "") -> dict:
        """ê°•í™”ëœ ì¢…í•© ë¶„ì„ (v3)"""
        
        try:
            template = self.load_crag_template()
            
            # ì´ë²¤íŠ¸ ë¶„ì„ ê°•í™”
            if not events_df.empty:
                event_table = self.create_enhanced_event_table(events_df)
                event_summary = self.analyze_event_patterns(events_df)
                summary_price = f"{len(events_df)}ê°œ ì´ë²¤íŠ¸ ê°ì§€ ({event_summary})"
                event_insight = self.generate_event_insights(events_df, matched_news_dict)
            else:
                event_table = "| ì‹œì  | ì´ë²¤íŠ¸ |\n|------|--------|\n| - | ê°ì§€ëœ ì´ë²¤íŠ¸ ì—†ìŒ |"
                summary_price = "ì´ë²¤íŠ¸ ì—†ìŒ"
                event_insight = "ì£¼ê°€ ì•ˆì •ì„¸, íŠ¹ë³„í•œ ë³€ë™ ìš”ì¸ ì—†ìŒ"

            # ë‰´ìŠ¤ ë¶„ì„ ê°•í™”
            news_analysis = self.analyze_news_comprehensive(matched_news_dict, news_impact)
            
            # ê²½ìŸì‚¬ ë¶„ì„
            competitor_analysis = self.analyze_competitors(competitor_news, stock_name)
            
            # ì‹œì¥ ë¶„ì„
            market_analysis = self.analyze_market_context(kospi_info, etf_info, industry_info)
            
            # íˆ¬ì ì¸ì‚¬ì´íŠ¸ ìƒì„±
            investment_insights = self.generate_investment_insights(
                events_df, news_impact, market_analysis, competitor_analysis
            )
            
            # í…œí”Œë¦¿ ë³€ìˆ˜ ë§¤í•‘ (ëª¨ë“  ê°€ëŠ¥í•œ ë³€ìˆ˜ í¬í•¨)
            template_vars = {
                'summary_price': summary_price,
                'sentiment_score': news_analysis['sentiment_score'],
                'sentiment_direction': news_analysis['sentiment_direction'],
                'news_timing_comment': news_analysis['timing_comment'],
                'kospi_info': kospi_info or "ì‹œì¥ ì •ë³´ ì—†ìŒ",
                'etf_info': etf_info or "ETF ì •ë³´ ì—†ìŒ", 
                'industry_info': industry_info or "ì—…ì¢… ì •ë³´ ì—†ìŒ",
                'event_table': event_table,
                'event_insight': event_insight,
                'top_news_titles': news_analysis['top_titles'],
                'impact_summary': news_analysis['impact_summary'],
                'competitor_summary': competitor_analysis,
                'insight_short': investment_insights['short_term'],
                'insight_mid': investment_insights['mid_term'],
                'risk_warning': investment_insights['risks'],
                'current_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'stock_name': stock_name,
                'analysis_date': date
            }
            
            # ì•ˆì „í•œ í…œí”Œë¦¿ í¬ë§·íŒ… (ë³€ìˆ˜ ê²€ì¦ í¬í•¨)
            try:
                # í…œí”Œë¦¿ì—ì„œ í•„ìš”í•œ ë³€ìˆ˜ ì¶”ì¶œ
                import re
                required_vars = set(re.findall(r'\{([^}:]+)', template))
                provided_vars = set(template_vars.keys())
                
                missing_vars = required_vars - provided_vars
                if missing_vars:
                    print(f"âš ï¸ ëˆ„ë½ëœ í…œí”Œë¦¿ ë³€ìˆ˜: {missing_vars}")
                    # ëˆ„ë½ëœ ë³€ìˆ˜ì— ê¸°ë³¸ê°’ í• ë‹¹
                    for var in missing_vars:
                        template_vars[var] = f"[{var} ì •ë³´ ì—†ìŒ]"
                
                print(f"ğŸ“ í…œí”Œë¦¿ í¬ë§·íŒ…: {len(required_vars)}ê°œ ë³€ìˆ˜ ì²˜ë¦¬")
                formatted_report = template.format(**template_vars)
                
            except KeyError as e:
                print(f"ğŸš¨ í…œí”Œë¦¿ ë³€ìˆ˜ ì˜¤ë¥˜: {e}")
                print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë³€ìˆ˜: {list(template_vars.keys())}")
                formatted_report = self.create_fallback_report(template_vars)
            except Exception as e:
                print(f"ğŸš¨ í…œí”Œë¦¿ í¬ë§·íŒ… ì˜¤ë¥˜: {e}")
                formatted_report = self.create_fallback_report(template_vars)
            
            print("ğŸ§  ê°•í™”ëœ CRAG ë¶„ì„ ì™„ë£Œ")
            
            return {
                "report": formatted_report,
                "summary": {
                    "ì´ë²¤íŠ¸_ìˆ˜": len(events_df),
                    "ë‰´ìŠ¤_ìˆ˜": news_analysis['total_news'],
                    "ê°ì„±_ì ìˆ˜": news_analysis['sentiment_score'],
                    "ê²½ìŸì‚¬_ë‰´ìŠ¤": len(competitor_news) if competitor_news else 0,
                    "ê³µì‹œ_ìˆ˜": sum(len(d) for d in matched_disclosures_dict.values()),
                    "ì‹œì¥_ìƒí™©": market_analysis,
                    "íˆ¬ì_ë“±ê¸‰": investment_insights['grade']
                }
            }
            
        except Exception as e:
            print(f"ğŸš¨ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            return {
                "report": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "summary": {"ì˜¤ë¥˜": str(e)}
            }

    def create_enhanced_event_table(self, events_df) -> str:
        """í–¥ìƒëœ ì´ë²¤íŠ¸ í…Œì´ë¸” ìƒì„±"""
        if events_df.empty:
            return "| ì‹œì  | ì´ë²¤íŠ¸ |\n|------|--------|\n| - | ê°ì§€ëœ ì´ë²¤íŠ¸ ì—†ìŒ |"
        
        table = "| ì‹œì  | ê°€ê²©ë³€í™” | ê±°ë˜ëŸ‰ë¹„ìœ¨ | RSI | ì´ë²¤íŠ¸ ìœ í˜• |\n"
        table += "|------|----------|-----------|-----|------------|\n"
        
        for _, row in events_df.head(10).iterrows():  # ìƒìœ„ 10ê°œë§Œ
            time_str = row['datetime'].strftime("%H:%M")
            pct = f"{row['pct_from_start']*100:+.2f}%"
            vol_ratio = f"{row.get('vol_ratio', 1.0):.1f}x" if pd.notna(row.get('vol_ratio')) else "N/A"
            rsi = f"{row.get('rsi', 50):.0f}" if pd.notna(row.get('rsi')) else "N/A"
            event_type = row['event_type'][:20] + "..." if len(row['event_type']) > 20 else row['event_type']
            
            table += f"| {time_str} | {pct} | {vol_ratio} | {rsi} | {event_type} |\n"
        
        return table

    def analyze_event_patterns(self, events_df) -> str:
        """ì´ë²¤íŠ¸ íŒ¨í„´ ë¶„ì„"""
        if events_df.empty:
            return "íŒ¨í„´ ì—†ìŒ"
        
        patterns = []
        
        # ì‹œê°„ëŒ€ë³„ ë¶„ì„
        events_df['hour'] = events_df['datetime'].dt.hour
        hourly_counts = events_df['hour'].value_counts()
        peak_hour = hourly_counts.index[0] if not hourly_counts.empty else None
        
        if peak_hour:
            if 9 <= peak_hour <= 10:
                patterns.append("ê°œì¥ ì´ˆë°˜ ì§‘ì¤‘")
            elif 14 <= peak_hour <= 15:
                patterns.append("ë§ˆê° ì „ í™œë°œ")
            else:
                patterns.append("ì •ê·œì¥ ì¤‘ë°˜ í™œë™")
        
        # ê°•ë„ë³„ ë¶„ì„
        strong_events = events_df[events_df['event_type'].str.contains('ê°•|ê¸‰|í­ì¦', na=False)]
        if len(strong_events) > 0:
            patterns.append(f"ê°•í•œ ë³€ë™ {len(strong_events)}íšŒ")
        
        return ", ".join(patterns) if patterns else "ì¼ë°˜ì  íŒ¨í„´"

    def generate_event_insights(self, events_df, matched_news_dict) -> str:
        """ì´ë²¤íŠ¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        if events_df.empty:
            return "ì£¼ê°€ ì•ˆì •ì„¸ ìœ ì§€, íŠ¹ë³„í•œ ë³€ë™ ìš”ì¸ í™•ì¸ë˜ì§€ ì•ŠìŒ"
        
        insights = []
        
        # ë‰´ìŠ¤ì™€ì˜ ìƒê´€ê´€ê³„
        total_matched = sum(len(news) for news in matched_news_dict.values())
        if total_matched > 0:
            insights.append(f"ì´ë²¤íŠ¸ ì‹œì  ì „í›„ {total_matched}ê°œ ë‰´ìŠ¤ í™•ì¸")
        else:
            insights.append("ë‰´ìŠ¤ ê¸°ë°˜ ì„¤ëª… ì–´ë ¤ì›€, ê¸°ìˆ ì /ìˆ˜ê¸‰ì  ìš”ì¸ ì¶”ì •")
        
        # ë³€ë™ì„± ë¶„ì„
        price_changes = events_df['pct_from_start'].abs()
        max_change = price_changes.max() * 100
        avg_change = price_changes.mean() * 100
        
        if max_change > 2.0:
            insights.append(f"ìµœëŒ€ {max_change:.1f}% ë³€ë™ìœ¼ë¡œ ë†’ì€ ë³€ë™ì„±")
        elif max_change > 1.0:
            insights.append(f"ì¤‘ê°„ ìˆ˜ì¤€ ë³€ë™ì„± ({max_change:.1f}%)")
        else:
            insights.append("ìƒëŒ€ì  ì•ˆì •ì  ì›€ì§ì„")
        
        # ê±°ë˜ëŸ‰ ë¶„ì„
        vol_events = events_df[events_df['event_type'].str.contains('ê±°ë˜ëŸ‰', na=False)]
        if len(vol_events) > 0:
            insights.append("ê±°ë˜ëŸ‰ ì´ìƒ ì‹ í˜¸ í¬í•¨")
        
        return ". ".join(insights)

    def analyze_news_comprehensive(self, matched_news_dict, news_impact) -> dict:
        """ì¢…í•© ë‰´ìŠ¤ ë¶„ì„"""
        all_news = [n for sublist in matched_news_dict.values() for n in sublist]
        
        sentiment_score = news_impact.get('sentiment_score', 0.0) if news_impact else 0.0
        
        if sentiment_score > 0.3:
            sentiment_direction = "ë§¤ìš° ê¸ì •"
        elif sentiment_score > 0.1:
            sentiment_direction = "ê¸ì •"
        elif sentiment_score > -0.1:
            sentiment_direction = "ì¤‘ë¦½"
        elif sentiment_score > -0.3:
            sentiment_direction = "ë¶€ì •"
        else:
            sentiment_direction = "ë§¤ìš° ë¶€ì •"
        
        # ë‰´ìŠ¤ íƒ€ì´ë° ë¶„ì„
        if sentiment_score > 0.2:
            timing_comment = "ê¸ì • ë‰´ìŠ¤ íë¦„ í™•ì¸"
        elif sentiment_score < -0.2:
            timing_comment = "ë¶€ì • ì¬ë£Œ ë¶€ê°"
        else:
            timing_comment = "ì¤‘ë¦½ì  ë³´ë„ ê¸°ì¡°"
        
        # ìƒìœ„ ë‰´ìŠ¤ ì¶”ì¶œ
        sorted_news = sorted(all_news, key=lambda x: x.get('relevance_score', 0), reverse=True)
        top_titles = "\n".join([
            f"  - [{n.get('relevance_score', 0):.1f}ì ] {n['title'][:50]}..."
            for n in sorted_news[:5]
        ]) if sorted_news else "- ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ"
        
        # ì„íŒ©íŠ¸ ìš”ì•½
        if news_impact:
            impact_summary = f"""
ê¸ì • ë‰´ìŠ¤ {news_impact.get('positive_count', 0)}ê°œ, 
ë¶€ì • ë‰´ìŠ¤ {news_impact.get('negative_count', 0)}ê°œ, 
ì¤‘ë¦½ ë‰´ìŠ¤ {news_impact.get('neutral_count', 0)}ê°œë¡œ 
{sentiment_direction} ê¸°ì¡° ìš°ì„¸
""".strip().replace('\n', ' ')
        else:
            impact_summary = "ë‰´ìŠ¤ ì˜í–¥ ë¶„ì„ ì •ë³´ ì—†ìŒ"
        
        return {
            'sentiment_score': sentiment_score,
            'sentiment_direction': sentiment_direction,
            'timing_comment': timing_comment,
            'top_titles': top_titles,
            'impact_summary': impact_summary,
            'total_news': len(all_news)
        }

    def analyze_competitors(self, competitor_news, stock_name) -> str:
        """ê²½ìŸì‚¬ ë¶„ì„"""
        if not competitor_news:
            return f"""
> â— **ê²½ìŸì‚¬ ë‰´ìŠ¤ ì •ë³´ ë¶€ì¡±**
> - {stock_name} ì§ì ‘ ê²½ìŸì‚¬ ë‰´ìŠ¤ ì—†ìŒ
> - ë™ì¢…ì—…ê³„ ë¹„êµë¶„ì„ ì œí•œì 
> - í–¥í›„ ì—…ì¢…ë³„ ë²¤ì¹˜ë§ˆí‚¹ í•„ìš”
"""
        
        competitor_summary = f"**ì£¼ìš” ê²½ìŸì‚¬ ë™í–¥ ({len(competitor_news)}ê±´)**\n"
        for i, news in enumerate(competitor_news[:3], 1):
            competitor_summary += f"{i}. [{news.get('competitor', 'N/A')}] {news['title'][:40]}...\n"
        
        if len(competitor_news) > 3:
            competitor_summary += f"   (ì™¸ {len(competitor_news)-3}ê±´ ì¶”ê°€)\n"
        
        return competitor_summary

    def analyze_market_context(self, kospi_info, etf_info, industry_info) -> str:
        """ì‹œì¥ ë§¥ë½ ë¶„ì„"""
        context_parts = []
        
        if "ì •ë³´ ì—†ìŒ" not in kospi_info:
            context_parts.append("ì½”ìŠ¤í”¼ ì •ë³´ í™•ì¸")
        if "ì •ë³´ ì—†ìŒ" not in etf_info:
            context_parts.append("ì„¹í„° ETF ë¹„êµ ê°€ëŠ¥")
        if "ì •ë³´ ì—†ìŒ" not in industry_info:
            context_parts.append("ì—…ì¢… ë¹„êµ ê°€ëŠ¥")
        
        if context_parts:
            return f"ì‹œì¥ ë§¥ë½ ë¶„ì„ ê°€ëŠ¥ ({', '.join(context_parts)})"
        else:
            return "ì‹œì¥ ë§¥ë½ ì •ë³´ ì œí•œì "

    def generate_investment_insights(self, events_df, news_impact, market_analysis, competitor_analysis) -> dict:
        """íˆ¬ì ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        
        # ë‹¨ê¸° ì „ë§
        event_count = len(events_df)
        sentiment = news_impact.get('sentiment_score', 0.0) if news_impact else 0.0
        
        if event_count > 5 and sentiment > 0.2:
            short_term = "ë†’ì€ ë³€ë™ì„± + ê¸ì • ë‰´ìŠ¤ â†’ ë‹¨ê¸° ìƒìŠ¹ ëª¨ë©˜í…€ ê¸°ëŒ€"
            grade = "B+"
        elif event_count > 3 or abs(sentiment) > 0.1:
            short_term = "ì¤‘ê°„ ìˆ˜ì¤€ ë³€ë™ì„± â†’ ë°©í–¥ì„± ì£¼ì˜ ê¹Šê²Œ ê´€ì°° í•„ìš”"
            grade = "B"
        else:
            short_term = "ì•ˆì •ì  íë¦„ â†’ í° ë³€í™” ì—†ì´ ë°•ìŠ¤ê¶Œ ì˜ˆìƒ"
            grade = "B-"
        
        # ì¤‘ê¸° ì „ë§
        if "ì œí•œì " in market_analysis and "ë¶€ì¡±" in competitor_analysis:
            mid_term = "ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ì¤‘ê¸° ë°©í–¥ì„± íŒë‹¨ ì–´ë ¤ì›€"
        elif sentiment > 0.2:
            mid_term = "ê¸ì •ì  ë‰´ìŠ¤ íë¦„ ì§€ì† ì‹œ ìƒìŠ¹ ì—¬ë ¥ ì¡´ì¬"
        else:
            mid_term = "ì¶”ê°€ ì¬ë£Œ ë¶€ì¬ ì‹œ íš¡ë³´ ê°€ëŠ¥ì„±"
        
        # ë¦¬ìŠ¤í¬
        risks = []
        if event_count > 5:
            risks.append("ë†’ì€ ë³€ë™ì„±ìœ¼ë¡œ ì¸í•œ ê¸‰ë½ ë¦¬ìŠ¤í¬")
        if "ì •ë³´ ë¶€ì¡±" in competitor_analysis:
            risks.append("ê²½ìŸ í™˜ê²½ ë¶ˆí™•ì‹¤ì„±")
        if abs(sentiment) < 0.1:
            risks.append("ëšœë ·í•œ ë°©í–¥ì„± ë¶€ì¬")
        
        risk_warning = ", ".join(risks) if risks else "ì¼ë°˜ì  ì‹œì¥ ë¦¬ìŠ¤í¬"
        
        return {
            'short_term': short_term,
            'mid_term': mid_term,
            'risks': risk_warning,
            'grade': grade
        }

    def create_fallback_report(self, template_vars) -> str:
        """í–¥ìƒëœ ê¸°ë³¸ ë¦¬í¬íŠ¸ ìƒì„± (í…œí”Œë¦¿ ì˜¤ë¥˜ì‹œ)"""
        
        sentiment_score = template_vars.get('sentiment_score', 0.0)
        sentiment_direction = template_vars.get('sentiment_direction', 'ì¤‘ë¦½')
        
        return f"""
ğŸ” **ì£¼ì‹ ë¶„ì„ ë¦¬í¬íŠ¸ (ê°„ì†Œ ë²„ì „)**

## ğŸ“Š **í•µì‹¬ ìš”ì•½**
- **ë¶„ì„ ê°œìš”**: {template_vars.get('summary_price', 'ì •ë³´ ì—†ìŒ')}
- **ë‰´ìŠ¤ ê°ì„±**: {sentiment_score:+.2f} ({sentiment_direction})
- **ì‹œì¥ ìƒí™©**: {template_vars.get('kospi_info', 'ì •ë³´ ì—†ìŒ')}

## ğŸ¯ **ì£¼ìš” ë°œê²¬ì‚¬í•­**
{template_vars.get('event_insight', 'ì£¼ìš” ì´ë²¤íŠ¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')}

## ğŸ“° **ë‰´ìŠ¤ ì˜í–¥ ë¶„ì„**
- **ê°ì„± ì ìˆ˜**: {sentiment_score:+.2f}
- **ì£¼ìš” ë‰´ìŠ¤**: 
{template_vars.get('top_news_titles', 'ë‰´ìŠ¤ ì •ë³´ ì—†ìŒ')}
- **ì˜í–¥ ë¶„ì„**: {template_vars.get('impact_summary', 'ë¶„ì„ ì •ë³´ ì—†ìŒ')}

## ğŸ¢ **ê²½ìŸì‚¬ í˜„í™©**
{template_vars.get('competitor_summary', 'ê²½ìŸì‚¬ ì •ë³´ ì—†ìŒ')}

## ğŸ’¡ **íˆ¬ì ê´€ì **
- **ë‹¨ê¸° ì „ë§**: {template_vars.get('insight_short', 'ì „ë§ ì •ë³´ ì—†ìŒ')}
- **ì¤‘ê¸° ê´€ì **: {template_vars.get('insight_mid', 'ì „ë§ ì •ë³´ ì—†ìŒ')}
- **ì£¼ìš” ë¦¬ìŠ¤í¬**: {template_vars.get('risk_warning', 'ë¦¬ìŠ¤í¬ ì •ë³´ ì—†ìŒ')}

## ğŸ“‹ **ì‹œì¥ ë§¥ë½**
- **ì „ì²´ ì‹œì¥**: {template_vars.get('kospi_info', 'N/A')}
- **ì—…ì¢… í˜„í™©**: {template_vars.get('industry_info', 'N/A')}
- **ì„¹í„° ETF**: {template_vars.get('etf_info', 'N/A')}

---
âš ï¸ **ì£¼ì˜**: í…œí”Œë¦¿ ì²˜ë¦¬ ì¤‘ ì¼ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ê°„ì†Œí™”ëœ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.  
ğŸ“ **ë¬¸ì˜**: ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ í…œí”Œë¦¿ íŒŒì¼ í™•ì¸ì„ ìš”ì²­í•˜ì„¸ìš”.

*ë³¸ ë¶„ì„ì€ AI ê¸°ë°˜ ìë™ ìƒì„±ì´ë©°, íˆ¬ì íŒë‹¨ì€ ì‚¬ìš©ì ì±…ì„ì…ë‹ˆë‹¤.*
"""

def search_stock_code(stock_name: str) -> tuple:
    """ì¢…ëª© ì½”ë“œ ê²€ìƒ‰ (ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)"""
    try:
        stock_db = get_stock_database()
        normalized_query = stock_name.replace(" ", "").lower()

        # ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
        for db_name, (code, full_name) in stock_db.items():
            db_name_normalized = db_name.lower().replace(" ", "")
            if normalized_query == db_name_normalized:
                print(f"âœ… ì¢…ëª© ë°œê²¬: {full_name} ({code})")
                return code, full_name

        # ë¶€ë¶„ ë§¤ì¹­
        candidates = []
        for db_name, (code, full_name) in stock_db.items():
            db_name_lower = db_name.lower()
            if normalized_query in db_name_lower or db_name_lower in normalized_query:
                candidates.append((code, full_name))

        if candidates:
            print(f"\nğŸ¯ '{stock_name}'ì™€ ìœ ì‚¬í•œ ì¢…ëª©ë“¤:")
            for i, (code, name) in enumerate(candidates[:5], 1):
                print(f"{i}. {name} ({code})")
            
            while True:
                try:
                    choice = input(f"\nì„ íƒ (1-{min(5, len(candidates))}): ").strip()
                    if choice.isdigit():
                        choice_num = int(choice)
                        if 1 <= choice_num <= min(5, len(candidates)):
                            return candidates[choice_num - 1]
                    print("ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                except KeyboardInterrupt:
                    return None, None

        # ìˆ˜ë™ ì…ë ¥
        print(f"\nâ— '{stock_name}'ë¥¼ ì¢…ëª© DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        manual_code = input("ğŸ‘‰ ì¢…ëª© ì½”ë“œë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 005930): ").strip()
        confirm_name = input("ğŸ‘‰ ì¢…ëª©ì˜ ì •ì‹ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì‚¼ì„±ì „ì): ").strip()

        if manual_code and confirm_name:
            print(f"âœ… ì…ë ¥ ì™„ë£Œ: {confirm_name} ({manual_code})")
            try:
                add_stock_entry(stock_name, manual_code, confirm_name)
            except Exception as e:
                print(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            return manual_code, confirm_name

    except Exception as e:
        print(f"ğŸš¨ ì¢…ëª© ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return None, None

def get_user_input():
    """ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° (ê°•í™”ëœ ê²€ì¦)"""
    print("ğŸš€ ê°•í™”ëœ CRAG ì£¼ì‹ ë¶„ì„ ì‹œìŠ¤í…œ v2.0")
    print("="*50)
    
    max_attempts = 3
    
    # ì¢…ëª© ì…ë ¥
    for attempt in range(max_attempts):
        try:
            stock_name = input(f"\nğŸ“ˆ ë¶„ì„í•  ì¢…ëª©ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì‹œë„: {attempt+1}/{max_attempts}): ").strip()
            if not stock_name:
                print("âŒ ì¢…ëª©ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
                
            stock_code, exact_name = search_stock_code(stock_name)
            if stock_code and exact_name:
                break
            else:
                print("âŒ ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                if attempt == max_attempts - 1:
                    print("âŒ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                    return None, None, None
        except KeyboardInterrupt:
            print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return None, None, None
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ë‚ ì§œ ì…ë ¥
    for attempt in range(max_attempts):
        try:
            print(f"\nğŸ“… ë¶„ì„ ë‚ ì§œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            print("í˜•ì‹: YYYY-MM-DD (ì˜ˆ: 2025-06-09) ë˜ëŠ” 'today'")
            
            date_input = input("ë‚ ì§œ: ").strip().lower()
            
            if date_input == "today":
                analysis_date = datetime.now().strftime("%Y-%m-%d")
                break
            elif date_input == "":
                print("âŒ ë‚ ì§œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            else:
                try:
                    # ë‚ ì§œ ìœ íš¨ì„± ê²€ì‚¬
                    parsed_date = datetime.strptime(date_input, "%Y-%m-%d")
                    if parsed_date > datetime.now():
                        print("âŒ ë¯¸ë˜ ë‚ ì§œëŠ” ì„ íƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                    analysis_date = date_input
                    break
                except ValueError:
                    print("âŒ ì˜¬ë°”ë¥¸ ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. (YYYY-MM-DD)")
                    continue
        except KeyboardInterrupt:
            print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return None, None, None
    
    print(f"\nâœ… ì„ íƒëœ ì¢…ëª©: {exact_name} ({stock_code})")
    print(f"âœ… ë¶„ì„ ë‚ ì§œ: {analysis_date}")
    
    confirm = input("\nğŸš€ ë¶„ì„ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
    if confirm not in ['y', 'yes']:
        print("ğŸ‘‹ ë¶„ì„ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return None, None, None
    
    return stock_code, exact_name, analysis_date

def main():
    """ê°•í™”ëœ CRAG ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    analyzer = CRAGAnalyzer()
    
    try:
        # ì‚¬ìš©ì ì…ë ¥
        user_input = get_user_input()
        if user_input[0] is None:
            return
        
        stock_code, stock_name, date = user_input
        
        print(f"\nğŸš€ {stock_name}({stock_code}) {date} ê°•í™”ëœ CRAG ë¶„ì„ ì‹œì‘")
        print("ğŸ’¡ ê³ ë„í™”ëœ ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„ ì‹œìŠ¤í…œ")
        print("="*70)

        # 1ë‹¨ê³„: ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘
        print("\nğŸ“Š 1ë‹¨ê³„: ê°•ê±´í•œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘")
        df = analyzer.robust_fetch_intraday_price(stock_code, date)
        
        # 2ë‹¨ê³„: ê³ ë„í™”ëœ ì´ë²¤íŠ¸ ê°ì§€
        print("\nğŸ¯ 2ë‹¨ê³„: ê³ ë„í™”ëœ ì´ë²¤íŠ¸ ê°ì§€")
        events = analyzer.enhanced_detect_price_events_by_day(df, threshold=0.005)
        print(f"âœ… ì£¼ê°€ ë°ì´í„°: {len(df)}ê°œ ì‹œì ")
        print(f"âœ… ê°ì§€ëœ ì´ë²¤íŠ¸: {len(events)}ê°œ")

        # 3ë‹¨ê³„: ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„
        print("\nğŸ“° 3ë‹¨ê³„: í–¥ìƒëœ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ê°ì„± ë¶„ì„")
        try:
            news_collector = EnhancedNewsCollector(analyzer.client_id, analyzer.client_secret)
            
            enhanced_news = news_collector.search_news_multi_strategy(
                stock_name=stock_name,
                date=date,
                days_before=3,
                days_after=0
            )
            
            news_impact = news_collector.analyze_news_impact(enhanced_news, stock_name)
            competitor_news = news_collector.get_competitor_news(stock_name, date)
            
            print(f"âœ… ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤: {len(enhanced_news)}ê°œ")
            print(f"âœ… ê°ì„± ë¶„ì„: ê¸ì • {news_impact['positive_count']}, ë¶€ì • {news_impact['negative_count']}, ì¤‘ë¦½ {news_impact['neutral_count']}")
            print(f"âœ… ê°ì„± ì ìˆ˜: {news_impact['sentiment_score']:+.3f}")
            print(f"âœ… ê²½ìŸì‚¬ ë‰´ìŠ¤: {len(competitor_news)}ê°œ")
            
        except Exception as e:
            print(f"âš ï¸ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            enhanced_news, news_impact, competitor_news = [], {}, []

        # 4ë‹¨ê³„: ê³µì‹œì •ë³´ ìˆ˜ì§‘
        print("\nğŸ“‹ 4ë‹¨ê³„: ê³µì‹œì •ë³´ ìˆ˜ì§‘")
        try:
            start_date = (datetime.strptime(date, "%Y-%m-%d") - timedelta(days=3)).strftime("%Y-%m-%d")
            disclosures = fetch_disclosures_with_fallback(stock_name, start_date, date)
            print(f"âœ… ìˆ˜ì§‘ëœ ê³µì‹œ: {len(disclosures)}ê°œ")
        except Exception as e:
            print(f"âš ï¸ ê³µì‹œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            disclosures = []

        # 5ë‹¨ê³„: ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë§¤ì¹­
        print("\nğŸ”— 5ë‹¨ê³„: CRAG ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„")
        try:
            # ë‰´ìŠ¤ í˜•ì‹ ë³€í™˜
            analyzed_news = []
            for news in enhanced_news:
                analyzed_news.append({
                    'title': news['title'],
                    'link': news['link'],
                    'pubDate': news['pubDate'],
                    'description': news.get('description', ''),
                    'relevance_score': news.get('relevance_score', 0),
                    'sentiment': 'neutral'
                })
            
            matched_news_dict = match_news_before_events(analyzed_news, events)
            matched_disclosures_dict = match_disclosures_before_events(disclosures, events, hours_before=72)
            
            total_matched_news = sum(len(news_list) for news_list in matched_news_dict.values())
            total_matched_disclosures = sum(len(disc_list) for disc_list in matched_disclosures_dict.values())
            print(f"âœ… ì¸ê³¼ê´€ê³„ ë§¤ì¹­ - ë‰´ìŠ¤: {total_matched_news}ê°œ, ê³µì‹œ: {total_matched_disclosures}ê°œ")
            
        except Exception as e:
            print(f"âš ï¸ ì¸ê³¼ê´€ê³„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            matched_news_dict, matched_disclosures_dict = {}, {}

        # 6ë‹¨ê³„: ì‹œì¥ ë§¥ë½ ìˆ˜ì§‘
        print("\nğŸ“ˆ 6ë‹¨ê³„: ì‹œì¥ ë§¥ë½ ì •ë³´ ìˆ˜ì§‘")
        try:
            date_fmt = datetime.strptime(date, "%Y-%m-%d").strftime("%Y.%m.%d")
            
            kospi_info = fetch_kospi_daily(date_fmt)
            kospi_line = (
                f"ì½”ìŠ¤í”¼ {kospi_info.get('close', 0):,.0f} ({kospi_info.get('rate', 0):+.2f}%)"
                if kospi_info and 'rate' in kospi_info else "ì½”ìŠ¤í”¼ ì •ë³´ ì—†ìŒ"
            )
            
            etf_info = fetch_sector_etf_daily(etf_code="091160", date_yyyymmdd=date_fmt)
            etf_line = (
                f"ë°˜ë„ì²´ETF {etf_info.get('rate', 0):+.2f}%"
                if etf_info and 'rate' in etf_info else "ì„¹í„°ETF ì •ë³´ ì—†ìŒ"
            )
            
            industry_info = fetch_industry_info_by_stock_code(stock_code)
            if industry_info and "ì—…ì¢…ëª…" in industry_info:
                industry_line = f"ì—…ì¢…({industry_info.get('ì—…ì¢…ëª…', 'N/A')}) {industry_info.get('ë“±ë½ë¥ ', 'N/A')}"
            else:
                industry_line = "ì—…ì¢… ì •ë³´ ì—†ìŒ"
                
            print(f"âœ… ì‹œì¥ ë§¥ë½: {kospi_line} | {etf_line} | {industry_line}")
            
        except Exception as e:
            print(f"âš ï¸ ì‹œì¥ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            kospi_line = etf_line = industry_line = "ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨"

        # 7ë‹¨ê³„: ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        print("\nğŸ§  7ë‹¨ê³„: ê°•í™”ëœ ì¢…í•© CRAG ë¶„ì„")
        try:
            analysis_result = analyzer.enhanced_comprehensive_analysis_v3(
                events, matched_news_dict, matched_disclosures_dict,
                stock_name, date, news_impact, competitor_news,
                kospi_info=kospi_line,
                etf_info=etf_line,
                industry_info=industry_line
            )
            print("âœ… CRAG ë¶„ì„ ì™„ë£Œ")
            
            # analysis_resultì—ì„œ report_contentì™€ summary ì¶”ì¶œ
            if isinstance(analysis_result, dict) and "error" not in analysis_result:
                report_content = analysis_result.get("report", "ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨")
                summary = analysis_result.get("summary", {})
            else:
                print("âš ï¸ ë¶„ì„ ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜, ê¸°ë³¸ ë¦¬í¬íŠ¸ ì‚¬ìš©")
                report_content = str(analysis_result)
                summary = {"ì˜¤ë¥˜": "ë¶„ì„ ì‹¤íŒ¨"}
                
        except Exception as e:
            print(f"ğŸš¨ ì¢…í•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            report_content = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            summary = {"ì˜¤ë¥˜": str(e)}
        
        # 8ë‹¨ê³„: ê²°ê³¼ ì¶œë ¥ ë° ì „ì†¡
        print("\n" + "="*70)
        print("ğŸ“„ CRAG ê¸°ë°˜ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")
        print("="*70)
        print(report_content)
        
        # 9ë‹¨ê³„: Slack ì „ì†¡
        print("\nğŸ“¨ 9ë‹¨ê³„: Slack ìš”ì•½ ì „ì†¡")
        try:
            final_message = f"ğŸ“ˆ *{stock_name} ({date}) CRAG ë¶„ì„ ì™„ë£Œ*\n\n" + \
                f"ğŸ¯ *í•µì‹¬ ì§€í‘œ*\n" + \
                f"â€¢ ì´ë²¤íŠ¸: {summary.get('ì´ë²¤íŠ¸_ìˆ˜', summary.get('ì´ë²¤íŠ¸ ìˆ˜', 0))}ê°œ\n" + \
                f"â€¢ ë‰´ìŠ¤: {summary.get('ë‰´ìŠ¤_ìˆ˜', summary.get('ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜', 0))}ê°œ (ê°ì„±: {summary.get('ê°ì„±_ì ìˆ˜', summary.get('ê°ì„± ì ìˆ˜', 0)):+.2f})\n" + \
                f"â€¢ ê²½ìŸì‚¬: {summary.get('ê²½ìŸì‚¬_ë‰´ìŠ¤', summary.get('ê²½ìŸì‚¬ ë‰´ìŠ¤ ìˆ˜', 0))}ê°œ\n" + \
                f"â€¢ ê³µì‹œ: {summary.get('ê³µì‹œ_ìˆ˜', summary.get('ê³µì‹œ ìˆ˜', 0))}ê°œ\n" + \
                f"â€¢ íˆ¬ìë“±ê¸‰: {summary.get('íˆ¬ì_ë“±ê¸‰', 'N/A')}\n\n" + \
                f"ğŸ“Š *ì‹œì¥ ë§¥ë½*\n" + \
                f"â€¢ {kospi_line}\n" + \
                f"â€¢ {etf_line}\n" + \
                f"â€¢ {industry_line}\n\n" + \
                f"---\n" + \
                f"â€¢ {report_content}\n" + \
                f"_ê°•í™”ëœ CRAG v2.0 ì‹œìŠ¤í…œ (ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ê¸°ë°˜)_"

            send_to_slack(final_message, analyzer.slack_url)
            print("âœ… Slack ì „ì†¡ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ Slack ì „ì†¡ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ë©”ì‹œì§€ë¼ë„ ì „ì†¡ ì‹œë„
            try:
                basic_message = f"ğŸ“ˆ {stock_name} ({date}) CRAG ë¶„ì„ ì™„ë£Œ (ì¼ë¶€ ì˜¤ë¥˜ ë°œìƒ)"
                send_to_slack(basic_message, analyzer.slack_url)
                print("âœ… ê¸°ë³¸ Slack ë©”ì‹œì§€ ì „ì†¡")
            except:
                print("âŒ Slack ì „ì†¡ ì™„ì „ ì‹¤íŒ¨")
        
        print(f"\nğŸ‰ {stock_name} CRAG ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ì‚¬ìš©ìê°€ í”„ë¡œê·¸ë¨ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        error_msg = f"ğŸš¨ CRAG ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}"
        print(error_msg)
        traceback.print_exc()
        
        try:
            send_to_slack(f"âŒ CRAG ë¶„ì„ ì‹¤íŒ¨: {error_msg}", analyzer.slack_url)
        except:
            print("Slack ì˜¤ë¥˜ ì•Œë¦¼ ì „ì†¡ë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()